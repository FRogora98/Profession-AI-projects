{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9de45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Dispositivo utilizzato: {device}')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6007917",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(r\"c:\\Users\\frogora\\OneDrive - BOARD\\Desktop\\Profession AI projects\\Profession-AI-projects\\7. Computer Vision\\progetto-finale-flowes\")\n",
    "train_dir = data_dir / \"train\"\n",
    "val_dir = data_dir / \"valid\" \n",
    "test_dir = data_dir / \"test\"\n",
    "\n",
    "for path in [train_dir, val_dir, test_dir]:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Cartella non trovata: {path}\")\n",
    "    print(f\"Cartella trovata: {path}\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 25\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b326e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images_in_folder(folder_path):\n",
    "    \"\"\"Conta il numero di immagini per ogni classe in una cartella\"\"\"\n",
    "    counts = {}\n",
    "    for class_folder in folder_path.iterdir():\n",
    "        if class_folder.is_dir():\n",
    "            jpg_count = len(list(class_folder.glob('*.jpg')))\n",
    "            counts[class_folder.name] = jpg_count\n",
    "    return counts\n",
    "\n",
    "train_counts = count_images_in_folder(train_dir)\n",
    "val_counts = count_images_in_folder(val_dir)\n",
    "test_counts = count_images_in_folder(test_dir)\n",
    "\n",
    "data_summary = pd.DataFrame({\n",
    "    'Train': train_counts,\n",
    "    'Validation': val_counts,\n",
    "    'Test': test_counts\n",
    "})\n",
    "\n",
    "print(\"Distribuzione del Dataset:\")\n",
    "print(data_summary)\n",
    "print(f\"\\nTotale immagini: {data_summary.sum().sum()}\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "data_summary.plot(kind='bar', ax=ax1, color=['skyblue', 'lightgreen', 'salmon'])\n",
    "ax1.set_title('Distribuzione Immagini per Set', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Numero di Immagini')\n",
    "ax1.set_xlabel('Classi')\n",
    "ax1.legend(title='Dataset Split')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "total_per_class = data_summary.sum(axis=1)\n",
    "colors = ['#FF9999', '#66B2FF']\n",
    "wedges, texts, autotexts = ax2.pie(total_per_class.values, labels=total_per_class.index, \n",
    "                                   autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "ax2.set_title('Distribuzione Totale per Classe', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "total_daisy = total_per_class['daisy']\n",
    "total_dandelion = total_per_class['dandelion']\n",
    "ratio = total_dandelion / total_daisy\n",
    "print(f\"\\nBilanciamento del dataset:\")\n",
    "print(f\"Rapporto Dandelion/Daisy: {ratio:.2f}\")\n",
    "if ratio > 1.3 or ratio < 0.7:\n",
    "    print(\"Dataset leggermente sbilanciato - considereremo weighted loss\")\n",
    "else:\n",
    "    print(\"Dataset relativamente bilanciato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_images(data_dir, num_samples=8):\n",
    "    \"\"\"Mostra immagini campione dal dataset\"\"\"\n",
    "    fig, axes = plt.subplots(2, num_samples//2, figsize=(16, 8))\n",
    "    fig.suptitle('Campioni del Dataset GreenTech Solutions', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    classes = ['daisy', 'dandelion']\n",
    "    \n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = data_dir / class_name\n",
    "        image_files = [f for f in class_dir.glob('*.jpg') if not f.name.startswith('._')][:num_samples//2]\n",
    "        \n",
    "        for j, img_path in enumerate(image_files):\n",
    "            try:\n",
    "                img = plt.imread(img_path)\n",
    "                axes[i, j].imshow(img)\n",
    "                axes[i, j].set_title(f'{class_name.capitalize()}', fontweight='bold')\n",
    "                axes[i, j].axis('off')\n",
    "            except Exception as e:\n",
    "                print(f\"Errore nella lettura di {img_path}: {e}\")\n",
    "                axes[i, j].text(0.5, 0.5, 'Errore\\ncaricamento\\nimmagine', \n",
    "                               ha='center', va='center', transform=axes[i, j].transAxes)\n",
    "                axes[i, j].set_title(f'{class_name.capitalize()} - Errore', fontweight='bold')\n",
    "                axes[i, j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_sample_images(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a92656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Trasformazioni configurate:\")\n",
    "print(\"  - Training: Resize, Flip, Rotation, ColorJitter, Affine, Normalize\")\n",
    "print(\"  - Validation/Test: Resize, Normalize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa58438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hidden_files(directory):\n",
    "    \"\"\"Rimuove i file nascosti (._*) dal dataset\"\"\"\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.startswith('._'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"Rimosso: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Errore rimozione {file_path}: {e}\")\n",
    "\n",
    "print(\"Pulizia file nascosti in corso...\")\n",
    "clean_hidden_files(train_dir)\n",
    "clean_hidden_files(val_dir)\n",
    "clean_hidden_files(test_dir)\n",
    "print(\"Pulizia completata!\")\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=val_test_transforms)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=val_test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "class_to_idx = train_dataset.class_to_idx\n",
    "\n",
    "print(f\"Dataset caricati:\")\n",
    "print(f\"- Training: {len(train_dataset)} immagini\")\n",
    "print(f\"- Validation: {len(val_dataset)} immagini\")\n",
    "print(f\"- Test: {len(test_dataset)} immagini\")\n",
    "print(f\"- Classi: {class_names}\")\n",
    "print(f\"- Mapping classi: {class_to_idx}\")\n",
    "\n",
    "class_counts = [len([f for f in (train_dir / class_name).glob('*.jpg')]) for class_name in class_names]\n",
    "total_samples = sum(class_counts)\n",
    "class_weights = [total_samples / (len(class_names) * count) for count in class_counts]\n",
    "\n",
    "print(f\"\\nBilanciamento classi:\")\n",
    "for i, (name, count, weight) in enumerate(zip(class_names, class_counts, class_weights)):\n",
    "    print(f\"- {name}: {count} immagini (peso: {weight:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClassifier(nn.Module):\n",
    "    \"\"\"Modello per classificazione fiori basato su transfer learning\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='efficientnet_b3', num_classes=2, pretrained=True):\n",
    "        super(FlowerClassifier, self).__init__()\n",
    "        \n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        \n",
    "        if hasattr(self.backbone, 'classifier'):\n",
    "            in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif hasattr(self.backbone, 'head'):\n",
    "            in_features = self.backbone.head.in_features\n",
    "            self.backbone.head = nn.Identity()\n",
    "        elif hasattr(self.backbone, 'fc'):\n",
    "            in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        else:\n",
    "            in_features = self.backbone.num_features\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "model = FlowerClassifier(model_name='efficientnet_b3', num_classes=NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Modello creato: EfficientNet-B3 con classificatore personalizzato\")\n",
    "print(f\"- Parametri totali: {total_params:,}\")\n",
    "print(f\"- Parametri addestrabili: {trainable_params:,}\")\n",
    "print(f\"- Dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46254ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.7, patience=3, min_lr=1e-7\n",
    ")\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "        return self.counter >= self.patience\n",
    "\n",
    "early_stopping = EarlyStopping(patience=7)\n",
    "\n",
    "print(\"Configurazione training:\")\n",
    "print(f\"  - Loss: CrossEntropyLoss con pesi {class_weights}\")\n",
    "print(f\"  - Optimizer: AdamW (lr={LEARNING_RATE}, weight_decay=0.01)\")\n",
    "print(f\"  - Scheduler: ReduceLROnPlateau\")\n",
    "print(f\"  - Early Stopping: patience=7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49607892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"Addestra il modello per una epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        total_samples += inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects.double() / total_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc.item()\n",
    "\n",
    "def validate_model(model, val_loader, criterion, device):\n",
    "    \"\"\"Valuta il modello sul validation set\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total_samples += inputs.size(0)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects.double() / total_samples\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return epoch_loss, epoch_acc.item(), epoch_f1\n",
    "\n",
    "print(\"Funzioni di training e validation definite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae36313",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "val_f1s = []\n",
    "best_f1 = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "print(\"Inizio training del modello GreenTech Solutions...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    s\n",
    "    val_loss, val_acc, val_f1 = validate_model(model, val_loader, criterion, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    val_f1s.append(val_f1)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print(f\"Nuovo miglior modello salvato! F1-Score: {val_f1:.4f}\")\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} ({epoch_time:.1f}s):\")\n",
    "    print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n",
    "    print(f\"  LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if early_stopping(val_loss):\n",
    "        print(f\"Early stopping attivato alla epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completato in {total_time//60:.0f}m {total_time%60:.0f}s\")\n",
    "print(f\"Miglior F1-Score: {best_f1:.4f}\")\n",
    "\n",
    "torch.save({\n",
    "    'epoch': epoch + 1,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'best_f1': best_f1,\n",
    "    'class_names': class_names,\n",
    "    'class_to_idx': class_to_idx\n",
    "}, 'greentech_flower_classifier.pth')\n",
    "\n",
    "print(\"Modello salvato come 'greentech_flower_classifier.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bf9ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('GreenTech Solutions - Metriche di Training', fontsize=16, fontweight='bold')\n",
    "\n",
    "epochs_range = range(1, len(train_losses) + 1)\n",
    "\n",
    "ax1.plot(epochs_range, train_losses, 'b-', label='Training Loss', linewidth=2)\n",
    "ax1.plot(epochs_range, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "ax1.set_title('Loss', fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(epochs_range, train_accs, 'b-', label='Training Accuracy', linewidth=2)\n",
    "ax2.plot(epochs_range, val_accs, 'r-', label='Validation Accuracy', linewidth=2)\n",
    "ax2.set_title('Accuracy', fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3.plot(epochs_range, val_f1s, 'g-', label='Validation F1-Score', linewidth=2)\n",
    "ax3.set_title('F1-Score (Macro)', fontweight='bold')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('F1-Score')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "lr_history = [LEARNING_RATE * (0.7 ** max(0, (i - 3) // 4)) for i in range(len(train_losses))]\n",
    "ax4.plot(epochs_range, lr_history, 'purple', linewidth=2)\n",
    "ax4.set_title('Learning Rate', fontweight='bold')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Learning Rate')\n",
    "ax4.set_yscale('log')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Statistiche finali del training:\")\n",
    "print(f\"- Miglior Validation F1-Score: {max(val_f1s):.4f}\")\n",
    "print(f\"- Miglior Validation Accuracy: {max(val_accs):.4f}\")\n",
    "print(f\"- Loss finale: {val_losses[-1]:.4f}\")\n",
    "print(f\"- Epochs completate: {len(train_losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbfb9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(model, test_loader, device, class_names):\n",
    "    \"\"\"Valuta il modello sul test set e genera report dettagliato\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return all_labels, all_preds, all_probs, accuracy, f1_macro, f1_weighted\n",
    "\n",
    "print(\"Valutazione finale sul test set...\")\n",
    "test_labels, test_preds, test_probs, test_acc, test_f1_macro, test_f1_weighted = evaluate_on_test(\n",
    "    model, test_loader, device, class_names\n",
    ")\n",
    "\n",
    "print(f\"Risultati finali sul Test Set:\")\n",
    "print(f\"- Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"- F1-Score Macro: {test_f1_macro:.4f}\")\n",
    "print(f\"- F1-Score Weighted: {test_f1_weighted:.4f}\")\n",
    "\n",
    "print(f\"Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "cm_normalized = confusion_matrix(test_labels, test_preds, normalize='true')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, \n",
    "            yticklabels=class_names, ax=ax1, cbar_kws={'label': 'Count'})\n",
    "ax1.set_title('Confusion Matrix - Conteggi Assoluti', fontweight='bold')\n",
    "ax1.set_xlabel('Predicted Label')\n",
    "ax1.set_ylabel('True Label')\n",
    "\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues', xticklabels=class_names, \n",
    "            yticklabels=class_names, ax=ax2, cbar_kws={'label': 'Rate'})\n",
    "ax2.set_title('Confusion Matrix - Normalizzata', fontweight='bold')\n",
    "ax2.set_xlabel('Predicted Label')\n",
    "ax2.set_ylabel('True Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Analisi per classe:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    tp = cm[i, i]\n",
    "    fp = cm[:, i].sum() - tp\n",
    "    fn = cm[i, :].sum() - tp\n",
    "    tn = cm.sum() - tp - fp - fn\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{class_name.upper()}:\")\n",
    "    print(f\"  - Precision: {precision:.4f}\")\n",
    "    print(f\"  - Recall (Sensitivity): {recall:.4f}\")\n",
    "    print(f\"  - Specificity: {specificity:.4f}\")\n",
    "    print(f\"  - Campioni corretti: {tp}/{tp+fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8383e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, test_loader, device, class_names, num_images=12):\n",
    "    \"\"\"Visualizza alcune predizioni del modello\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    dataiter = iter(test_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    fig.suptitle('Predizioni del Modello GreenTech Solutions', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i in range(min(num_images, len(images))):\n",
    "        img = images[i].cpu().numpy().transpose((1, 2, 0))\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        true_label = class_names[labels[i]]\n",
    "        pred_label = class_names[preds[i]]\n",
    "        confidence = probs[i][preds[i]].item()\n",
    "        \n",
    "        color = 'green' if labels[i] == preds[i] else 'red'\n",
    "        \n",
    "        ax = axes[i//4, i%4]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.3f}', \n",
    "                    color=color, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor(color)\n",
    "            spine.set_linewidth(3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, test_loader, device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_errors(model, test_loader, device, class_names):\n",
    "    \"\"\"Analizza gli errori del modello per identificare pattern\"\"\"\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            incorrect = preds != labels\n",
    "            if incorrect.any():\n",
    "                for i in range(len(labels)):\n",
    "                    if incorrect[i]:\n",
    "                        confidence = probs[i][preds[i]].item()\n",
    "                        true_conf = probs[i][labels[i]].item()\n",
    "                        errors.append({\n",
    "                            'true_class': class_names[labels[i]],\n",
    "                            'pred_class': class_names[preds[i]],\n",
    "                            'confidence': confidence,\n",
    "                            'true_confidence': true_conf,\n",
    "                            'batch_idx': batch_idx,\n",
    "                            'image_idx': i\n",
    "                        })\n",
    "    \n",
    "    if errors:\n",
    "        errors_df = pd.DataFrame(errors)\n",
    "        \n",
    "        print(f\"Analisi errori ({len(errors)} errori totali):\")\n",
    "        print(f\"\\nDistribuzione errori per classe:\")\n",
    "        error_by_true = errors_df.groupby('true_class').size()\n",
    "        for class_name in class_names:\n",
    "            count = error_by_true.get(class_name, 0)\n",
    "            total = sum(1 for label in test_labels if class_names[label] == class_name)\n",
    "            error_rate = count / total if total > 0 else 0\n",
    "            print(f\"  - {class_name}: {count}/{total} errori ({error_rate:.2%})\")\n",
    "        \n",
    "        print(f\"\\nConfidenza media negli errori:\")\n",
    "        avg_conf = errors_df['confidence'].mean()\n",
    "        avg_true_conf = errors_df['true_confidence'].mean()\n",
    "        print(f\"  - Confidenza predizione errata: {avg_conf:.3f}\")\n",
    "        print(f\"  - Confidenza classe vera: {avg_true_conf:.3f}\")\n",
    "        \n",
    "        high_conf_errors = errors_df[errors_df['confidence'] > 0.7]\n",
    "        print(f\"Errori con alta confidenza (>70%): {len(high_conf_errors)}\")\n",
    "        if len(high_conf_errors) > 0:\n",
    "            print(\"Questi potrebbero essere casi genuinamente difficili o errori di labeling.\")\n",
    "    \n",
    "    return errors\n",
    "\n",
    "errors = analyze_errors(model, test_loader, device, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
