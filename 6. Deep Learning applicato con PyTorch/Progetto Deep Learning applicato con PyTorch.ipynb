{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befeef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5364b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# URL del dataset dalla traccia\n",
    "dataset_url = \"https://proai-datasets.s3.eu-west-3.amazonaws.com/dataset_food_classification.zip\"\n",
    "\n",
    "def download_and_extract_dataset():\n",
    "    \"\"\"\n",
    "    Scarica ed estrae il dataset nella cartella ./dataset\n",
    "    \"\"\"\n",
    "    if not os.path.exists('./dataset'):\n",
    "        print(\"Dataset non trovato. Scaricamento in corso...\")\n",
    "        \n",
    "        # Crea la directory se non esiste\n",
    "        os.makedirs('./dataset', exist_ok=True)\n",
    "        \n",
    "        # Scarica il file zip\n",
    "        zip_path = './dataset.zip'\n",
    "        try:\n",
    "            print(f\"Scaricamento da {dataset_url}...\")\n",
    "            urllib.request.urlretrieve(dataset_url, zip_path)\n",
    "            print(\"Download completato!\")\n",
    "            \n",
    "            # Estrae il contenuto\n",
    "            print(\"Estrazione del dataset...\")\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall('./dataset')\n",
    "            \n",
    "            # Rimuove il file zip\n",
    "            os.remove(zip_path)\n",
    "            print(\"Dataset estratto con successo in ./dataset/\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Errore durante il download: {e}\")\n",
    "            print(\"Per favore scarica manualmente il dataset e inseriscilo nella cartella './dataset'\")\n",
    "    else:\n",
    "        print(\"Dataset già presente nella cartella ./dataset/\")\n",
    "\n",
    "# Esegui il download\n",
    "download_and_extract_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset'\n",
    "\n",
    "# Trasformazioni per training con data augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Trasformazioni per validation e test (senza augmentation)\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a18cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = datasets.ImageFolder(data_dir, transform=train_transforms)\n",
    "\n",
    "# Suddivisione dataset: 70% train, 15% validation, 15% test\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    full_dataset, [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Applica trasformazioni senza augmentation a val e test\n",
    "val_dataset.dataset.transform = val_test_transforms\n",
    "test_dataset.dataset.transform = val_test_transforms\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = full_dataset.classes\n",
    "print(f\"Classi: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7687ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per visualizzare immagini denormalizzate\n",
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Visualizza esempi del dataset\n",
    "inputs, classes = next(iter(train_loader))\n",
    "out = torchvision.utils.make_grid(inputs[:8])\n",
    "imshow(out, title=[class_names[x] for x in classes[:8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff8081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica ResNet18 pre-addestrato\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Congela i parametri pre-addestrati (transfer learning)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modifica il classificatore finale per le nostre classi\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454fc2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe531445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=15):\n",
    "    best_acc = 0.0\n",
    "    best_model_wts = model.state_dict()\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        model.train()\n",
    "        running_loss, running_corrects = 0.0, 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / train_size\n",
    "        epoch_acc = running_corrects.double() / train_size\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_corrects = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "        val_loss = val_loss / val_size\n",
    "        val_acc = val_corrects.double() / val_size\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = model.state_dict()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "model, train_losses, val_losses = train_model(model, criterion, optimizer, scheduler, num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358677fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning: scongela gli ultimi layer per ottimizzazione avanzata\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "model, train_losses, val_losses = train_model(model, criterion, optimizer, scheduler, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione finale sul test set\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "# Visualizza confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'best_food_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search per ottimizzazione degli iperparametri\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "\n",
    "print(\"GRID SEARCH DEGLI IPERPARAMETRI\")\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-4, 5e-4, 1e-3],\n",
    "    'batch_size': [16, 32],\n",
    "    'optimizer_type': ['Adam', 'SGD'],\n",
    "    'weight_decay': [1e-4, 1e-5]\n",
    "}\n",
    "\n",
    "def create_model():\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
    "    return model.to(device)\n",
    "\n",
    "def evaluate_model_quick(model, val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "def train_model_quick(model, criterion, optimizer, num_epochs=5):\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    val_acc = evaluate_model_quick(model, val_loader)\n",
    "    return val_acc\n",
    "\n",
    "# Esecuzione Grid Search\n",
    "best_params = None\n",
    "best_val_acc = 0.0\n",
    "results = []\n",
    "\n",
    "print(\"Inizio Grid Search...\")\n",
    "print(f\"Testando {len(list(itertools.product(*param_grid.values())))} combinazioni di parametri\")\n",
    "\n",
    "for i, params in enumerate(itertools.product(*param_grid.values())):\n",
    "    lr, bs, opt_type, wd = params\n",
    "    \n",
    "    print(f\"\\nTesting combinazione {i+1}: LR={lr}, BS={bs}, OPT={opt_type}, WD={wd}\")\n",
    "    \n",
    "    try:\n",
    "        test_model = create_model()\n",
    "        \n",
    "        if bs != 32:\n",
    "            temp_train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "            temp_val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=False)\n",
    "        else:\n",
    "            temp_train_loader = train_loader\n",
    "            temp_val_loader = val_loader\n",
    "        \n",
    "        if opt_type == 'Adam':\n",
    "            optimizer = optim.Adam(test_model.fc.parameters(), lr=lr, weight_decay=wd)\n",
    "        else:\n",
    "            optimizer = optim.SGD(test_model.fc.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        for param in test_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in test_model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        original_train_loader = train_loader\n",
    "        original_val_loader = val_loader\n",
    "        \n",
    "        if bs != 32:\n",
    "            globals()['train_loader'] = temp_train_loader\n",
    "            globals()['val_loader'] = temp_val_loader\n",
    "        \n",
    "        val_acc = train_model_quick(test_model, criterion, optimizer, num_epochs=3)\n",
    "        \n",
    "        globals()['train_loader'] = original_train_loader\n",
    "        globals()['val_loader'] = original_val_loader\n",
    "        \n",
    "        results.append({\n",
    "            'params': {'lr': lr, 'batch_size': bs, 'optimizer': opt_type, 'weight_decay': wd},\n",
    "            'val_accuracy': val_acc\n",
    "        })\n",
    "        \n",
    "        print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_params = {'lr': lr, 'batch_size': bs, 'optimizer': opt_type, 'weight_decay': wd}\n",
    "            print(\"Nuovo miglior risultato!\")\n",
    "        \n",
    "        del test_model\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Errore con parametri {params}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nRISULTATI GRID SEARCH\")\n",
    "print(f\"Migliori parametri: {best_params}\")\n",
    "print(f\"Migliore validation accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 configurazioni:\")\n",
    "sorted_results = sorted(results, key=lambda x: x['val_accuracy'], reverse=True)\n",
    "for i, result in enumerate(sorted_results[:5]):\n",
    "    print(f\"{i+1}. Accuracy: {result['val_accuracy']:.4f} - Params: {result['params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09cb76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training finale con i migliori iperparametri trovati\n",
    "print(\"TRAINING FINALE CON MIGLIORI IPERPARAMETRI\")\n",
    "\n",
    "if best_params:\n",
    "    print(f\"Utilizzo i migliori parametri trovati: {best_params}\")\n",
    "    \n",
    "    final_model = create_model()\n",
    "    \n",
    "    if best_params['optimizer'] == 'Adam':\n",
    "        final_optimizer = optim.Adam(final_model.fc.parameters(), \n",
    "                                   lr=best_params['lr'], \n",
    "                                   weight_decay=best_params['weight_decay'])\n",
    "    else:\n",
    "        final_optimizer = optim.SGD(final_model.fc.parameters(), \n",
    "                                  lr=best_params['lr'], \n",
    "                                  weight_decay=best_params['weight_decay'], \n",
    "                                  momentum=0.9)\n",
    "    \n",
    "    final_criterion = nn.CrossEntropyLoss()\n",
    "    final_scheduler = optim.lr_scheduler.StepLR(final_optimizer, step_size=7, gamma=0.1)\n",
    "    \n",
    "    print(\"Inizio training finale...\")\n",
    "    \n",
    "    # Prima fase: solo FC layer\n",
    "    for param in final_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in final_model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    final_model, train_losses_final, val_losses_final = train_model(\n",
    "        final_model, final_criterion, final_optimizer, final_scheduler, num_epochs=10\n",
    "    )\n",
    "    \n",
    "    # Seconda fase: fine-tuning degli ultimi layer\n",
    "    print(\"\\nInizio fine-tuning degli ultimi layer...\")\n",
    "    for name, param in final_model.named_parameters():\n",
    "        if \"layer4\" in name or \"fc\" in name:\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    # Riduce il learning rate per il fine-tuning\n",
    "    for param_group in final_optimizer.param_groups:\n",
    "        param_group['lr'] = param_group['lr'] * 0.1\n",
    "    \n",
    "    final_model, _, _ = train_model(\n",
    "        final_model, final_criterion, final_optimizer, final_scheduler, num_epochs=5\n",
    "    )\n",
    "    \n",
    "    torch.save(final_model.state_dict(), 'best_food_classifier_optimized.pth')\n",
    "    print(\"Modello finale salvato come 'best_food_classifier_optimized.pth'\")\n",
    "\n",
    "else:\n",
    "    print(\"Usando il modello già addestrato...\")\n",
    "    final_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5446929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione finale completa su tutti i dataset\n",
    "print(\"VALUTAZIONE FINALE DEL MODELLO\")\n",
    "\n",
    "final_model.eval()\n",
    "\n",
    "# Valutazione su training set\n",
    "print(\"Valutazione su Training Set:\")\n",
    "train_preds, train_labels = [], []\n",
    "train_correct = 0\n",
    "train_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = final_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        train_preds.extend(preds.cpu().numpy())\n",
    "        train_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "train_accuracy = train_correct / train_total\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Valutazione su validation set\n",
    "print(\"\\nValutazione su Validation Set:\")\n",
    "val_preds, val_labels = [], []\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = final_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        val_preds.extend(preds.cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_correct += (preds == labels).sum().item()\n",
    "        val_total += labels.size(0)\n",
    "\n",
    "val_accuracy = val_correct / val_total\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Valutazione su test set\n",
    "print(\"\\nValutazione su Test Set:\")\n",
    "test_preds, test_labels = [], []\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = final_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        test_correct += (preds == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "test_accuracy = test_correct / test_total\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Riepilogo risultati\n",
    "print(\"\\nRIEPILOGO ACCURACY:\")\n",
    "print(f\"Training Accuracy:   {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
    "print(f\"Test Accuracy:       {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Analisi overfitting\n",
    "overfitting = train_accuracy - test_accuracy\n",
    "print(f\"\\nOverfitting (Train - Test): {overfitting:.4f}\")\n",
    "if overfitting < 0.05:\n",
    "    print(\"Modello ben generalizzato (basso overfitting)\")\n",
    "elif overfitting < 0.15:\n",
    "    print(\"Modello moderatamente overfittato\")\n",
    "else:\n",
    "    print(\"Modello overfittato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c1fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report e Confusion Matrix dettagliati\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "\n",
    "print(\"CLASSIFICATION REPORT SUL TEST SET\")\n",
    "print(\"\\nClassification Report completo:\")\n",
    "report = classification_report(test_labels, test_preds, target_names=class_names, \n",
    "                             output_dict=True, zero_division=0)\n",
    "print(classification_report(test_labels, test_preds, target_names=class_names, zero_division=0))\n",
    "\n",
    "# Metriche aggregate\n",
    "print(f\"\\nAccuracy complessiva: {report['accuracy']:.4f}\")\n",
    "print(f\"Macro avg F1-score: {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"Weighted avg F1-score: {report['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nCONFUSION MATRIX\")\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "print(f\"Dimensione Confusion Matrix: {cm.shape}\")\n",
    "print(f\"Classi: {class_names}\")\n",
    "\n",
    "# Visualizzazione grafica\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Numero di predizioni'})\n",
    "plt.title('Confusion Matrix - Test Set', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Predicted Class', fontsize=12)\n",
    "plt.ylabel('True Class', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix normalizzata\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Percentuale'})\n",
    "plt.title('Confusion Matrix Normalizzata - Test Set', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Predicted Class', fontsize=12)\n",
    "plt.ylabel('True Class', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analisi errori per classe\n",
    "print(\"\\nANALISI ERRORI PER CLASSE\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    true_positives = cm[i, i]\n",
    "    false_positives = cm[:, i].sum() - true_positives\n",
    "    false_negatives = cm[i, :].sum() - true_positives\n",
    "    \n",
    "    if cm[i, :].sum() > 0:\n",
    "        class_accuracy = true_positives / cm[i, :].sum()\n",
    "        print(f\"\\n{class_name}:\")\n",
    "        print(f\"  - Accuracy di classe: {class_accuracy:.3f}\")\n",
    "        print(f\"  - True Positives: {true_positives}\")\n",
    "        print(f\"  - False Positives: {false_positives}\")\n",
    "        print(f\"  - False Negatives: {false_negatives}\")\n",
    "        \n",
    "        if false_negatives > 0:\n",
    "            main_errors = []\n",
    "            for j, other_class in enumerate(class_names):\n",
    "                if i != j and cm[i, j] > 0:\n",
    "                    main_errors.append(f\"{other_class} ({cm[i, j]})\")\n",
    "            if main_errors:\n",
    "                print(f\"  - Principalmente confuso con: {', '.join(main_errors[:3])}\")\n",
    "\n",
    "# Salvataggio risultati\n",
    "results_summary = {\n",
    "    'train_accuracy': train_accuracy,\n",
    "    'val_accuracy': val_accuracy, \n",
    "    'test_accuracy': test_accuracy,\n",
    "    'best_hyperparams': best_params if 'best_params' in locals() else None,\n",
    "    'overfitting': overfitting,\n",
    "    'macro_f1': report['macro avg']['f1-score'],\n",
    "    'weighted_f1': report['weighted avg']['f1-score']\n",
    "}\n",
    "\n",
    "print(f\"\\nRisultati completi: {results_summary}\")\n",
    "\n",
    "# Salva file CSV\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "cm_df.to_csv('confusion_matrix.csv')\n",
    "report_df.to_csv('classification_report.csv')\n",
    "print(\"File salvati: confusion_matrix.csv, classification_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0119f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZZAZIONE RISULTATI E LEARNING CURVES\n",
    "print(\"VISUALIZZAZIONE RISULTATI\")\n",
    "\n",
    "# Learning Curves\n",
    "if 'train_losses' in locals() and 'val_losses' in locals():\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Training e Validation Loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)\n",
    "    plt.plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "    plt.title('Training vs Validation Loss', fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Accuracy Comparison\n",
    "    plt.subplot(1, 3, 2)\n",
    "    accuracies = [train_accuracy, val_accuracy, test_accuracy]\n",
    "    datasets = ['Train', 'Validation', 'Test']\n",
    "    colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "    \n",
    "    bars = plt.bar(datasets, accuracies, color=colors, alpha=0.7, edgecolor='black')\n",
    "    plt.title('Accuracy per Dataset', fontweight='bold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Aggiungi valori sopra le barre\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Plot 3: F1-score per classe\n",
    "    plt.subplot(1, 3, 3)\n",
    "    f1_scores = [report[class_name]['f1-score'] for class_name in class_names]\n",
    "    plt.barh(range(len(class_names)), f1_scores, color='mediumpurple', alpha=0.7)\n",
    "    plt.yticks(range(len(class_names)), class_names)\n",
    "    plt.xlabel('F1-Score')\n",
    "    plt.title('F1-Score per Classe', fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Esempi di predizioni del modello\n",
    "print(\"\\nESEMPI DI PREDIZIONI\")\n",
    "\n",
    "def denormalize_image(tensor):\n",
    "    \"\"\"Denormalizza l'immagine per la visualizzazione\"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])\n",
    "    tensor = tensor.clone()\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return torch.clamp(tensor, 0, 1)\n",
    "\n",
    "final_model.eval()\n",
    "examples_shown = 0\n",
    "max_examples = 12\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = final_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Converti le probabilità in percentuali\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        \n",
    "        for i in range(inputs.size(0)):\n",
    "            if examples_shown >= max_examples:\n",
    "                break\n",
    "                \n",
    "            img = denormalize_image(inputs[i].cpu())\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "            \n",
    "            true_label = class_names[labels[i]]\n",
    "            pred_label = class_names[preds[i]]\n",
    "            confidence = probs[i][preds[i]].item() * 100\n",
    "            \n",
    "            color = 'green' if preds[i] == labels[i] else 'red'\n",
    "            \n",
    "            plt.subplot(3, 4, examples_shown + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%', \n",
    "                     color=color, fontweight='bold', fontsize=10)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            examples_shown += 1\n",
    "        \n",
    "        if examples_shown >= max_examples:\n",
    "            break\n",
    "\n",
    "plt.suptitle('Esempi di Predizioni (Verde=Corretto, Rosso=Errato)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Riepilogo finale del progetto\n",
    "print(\"\\nSTATISTICHE FINALI DEL PROGETTO\")\n",
    "print(\"Dataset:\", len(class_names), \"classi,\", len(full_dataset), \"immagini totali\")\n",
    "print(\"Training:\", train_size, \"immagini\")\n",
    "print(\"Validation:\", val_size, \"immagini\") \n",
    "print(\"Test:\", test_size, \"immagini\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Macro F1-Score: {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"Weighted F1-Score: {report['weighted avg']['f1-score']:.4f}\")\n",
    "if 'best_params' in locals() and best_params:\n",
    "    print(\"Migliori iperparametri:\", best_params)\n",
    "print(\"Modello salvato: best_food_classifier_optimized.pth\")\n",
    "print(\"Report salvati: confusion_matrix.csv, classification_report.csv\")\n",
    "print(\"PROGETTO COMPLETATO CON SUCCESSO!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
